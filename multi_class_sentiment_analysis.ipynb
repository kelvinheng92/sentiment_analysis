{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Multi_class_sentiment_analysis.ipynb","provenance":[{"file_id":"https://github.com/kelvinheng92/sentiment_analysis/blob/master/baseline.ipynb","timestamp":1589457930206},{"file_id":"https://github.com/kelvinheng92/sentiment_analysis/blob/master/baseline.ipynb","timestamp":1589417551888}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"D0fSKmcvTUU3","colab_type":"text"},"source":["# Data Preparation"]},{"cell_type":"code","metadata":{"id":"L1xB2xwRTZKg","colab_type":"code","colab":{}},"source":["import torch\n","from torchtext import data, datasets\n","import random\n","\n","SEED = 1992\n","\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","TEXT = data.Field(tokenize = 'spacy', batch_first=True)\n","LABEL = data.LabelField()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jxyR5l5oTjAh","colab_type":"code","outputId":"668112ac-b6ee-4035-dc4d-9d6e06e9750f","executionInfo":{"status":"ok","timestamp":1590631447483,"user_tz":-480,"elapsed":10041,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["train_data, test_data = datasets.TREC.splits(TEXT, LABEL, fine_grained=False)\n","valid_data, test_data = test_data.split(split_ratio = 0.5, random_state = random.seed(SEED)) #Further split test set into validation and test set"],"execution_count":2,"outputs":[{"output_type":"stream","text":["downloading train_5500.label\n"],"name":"stdout"},{"output_type":"stream","text":["train_5500.label: 100%|██████████| 336k/336k [00:00<00:00, 868kB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["downloading TREC_10.label\n"],"name":"stdout"},{"output_type":"stream","text":["TREC_10.label: 100%|██████████| 23.4k/23.4k [00:00<00:00, 297kB/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ddKoNplZUY7Q","colab_type":"code","outputId":"2f88fcb0-afb5-4db0-fd22-116543dddf23","executionInfo":{"status":"ok","timestamp":1590631459220,"user_tz":-480,"elapsed":1103,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["print(f'Number of training examples: {len(train_data)}')\n","print(f'Number of validation examples: {len(valid_data)}')\n","print(f'Number of testing examples: {len(test_data)}')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Number of training examples: 5452\n","Number of validation examples: 250\n","Number of testing examples: 250\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IhV_vj1GUuZZ","colab_type":"code","outputId":"2a3f40fd-ff82-4135-8a18-b821e6e41e10","executionInfo":{"status":"ok","timestamp":1590631704068,"user_tz":-480,"elapsed":1137,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(vars(train_data.examples[0]))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["{'text': ['How', 'did', 'serfdom', 'develop', 'in', 'and', 'then', 'leave', 'Russia', '?'], 'label': 'DESC'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DW8OoSamoN_5","colab_type":"code","outputId":"afe5f7c1-0041-4bac-99be-9fffc24059bd","executionInfo":{"status":"ok","timestamp":1590632175248,"user_tz":-480,"elapsed":443806,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["MAX_VOCAB_SIZE = 25_000\n","TEXT.build_vocab(train_data,\n","                 max_size = MAX_VOCAB_SIZE,\n","                 vectors = \"glove.6B.100d\",\n","                 unk_init = torch.Tensor.normal_)\n","LABEL.build_vocab(train_data)"],"execution_count":5,"outputs":[{"output_type":"stream","text":[".vector_cache/glove.6B.zip: 862MB [06:30, 2.21MB/s]                           \n","100%|█████████▉| 399287/400000 [00:22<00:00, 18263.59it/s]"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"xKpI5orppdF4","colab_type":"code","outputId":"869eb66c-3b66-4481-9308-2247fa73a053","executionInfo":{"status":"ok","timestamp":1590632175250,"user_tz":-480,"elapsed":441771,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["vars(LABEL.vocab)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'freqs': Counter({'ABBR': 86,\n","          'DESC': 1162,\n","          'ENTY': 1250,\n","          'HUM': 1223,\n","          'LOC': 835,\n","          'NUM': 896}),\n"," 'itos': ['ENTY', 'HUM', 'DESC', 'NUM', 'LOC', 'ABBR'],\n"," 'stoi': defaultdict(<function torchtext.vocab._default_unk_index>,\n","             {'ABBR': 5, 'DESC': 2, 'ENTY': 0, 'HUM': 1, 'LOC': 4, 'NUM': 3}),\n"," 'vectors': None}"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"_zHC1He0oqbn","colab_type":"code","outputId":"259741a5-5e95-4582-8b59-9433238793ae","executionInfo":{"status":"ok","timestamp":1590632176496,"user_tz":-480,"elapsed":1228,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(f'There are {len(TEXT.vocab)} unique tokens in TEXT vocabulary')\n","print(f'There are {len(LABEL.vocab)} unique tokens in LABEL vocabulary')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["There are 9343 unique tokens in TEXT vocabulary\n","There are 6 unique tokens in LABEL vocabulary\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mwaiWFisr1IW","colab_type":"code","outputId":"e7efdc71-bc01-4e4e-8da0-a0853cb82fce","executionInfo":{"status":"ok","timestamp":1590632176496,"user_tz":-480,"elapsed":1214,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(vars(TEXT.vocab).keys())\n","print(vars(LABEL.vocab).keys())"],"execution_count":8,"outputs":[{"output_type":"stream","text":["dict_keys(['freqs', 'itos', 'stoi', 'vectors'])\n","dict_keys(['freqs', 'itos', 'stoi', 'vectors'])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Oa95Dc4WrQ4l","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 64\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits((train_data, valid_data, test_data),\n","                                                                           batch_size = BATCH_SIZE,\n","                                                                           device = device)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zk5IUombrJRC","colab_type":"text"},"source":["# Model Architecture"]},{"cell_type":"code","metadata":{"id":"V0GhJG2Jt3I_","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class CNN(nn.Module):\n","  def __init__(self, input_dim, emb_dim, num_filters,\n","               filter_sizes, output_dim, dropout, pad_idx):\n","    \n","    super().__init__() # init from super class in nn.module\n","    self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx = pad_idx)\n","\n","    self.convs = nn.ModuleList([nn.Conv2d(in_channels = 1,\n","                                out_channels = num_filters,\n","                                kernel_size = (fs, emb_dim))\n","                                for fs in filter_sizes\n","                                ])\n","\n","    self.fc = nn.Linear(num_filters * len(filter_sizes) , output_dim)\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, text):\n","    # text has dimension of (batch_size, sentence_length)\n","    embedding_output = self.embedding(text)\n","    # embedding_output has dimension of (batch_size, sentence_length, emb_dim)\n","    embedding_output = embedding_output.unsqueeze(1)\n","    # embedding_output has dimension of (batch_size, 1, sentence_length, emb_dim)\n","\n","    convs_output = [F.relu(conv(embedding_output).squeeze(3)) for conv in self.convs]\n","    # Each of the tensor in convs_output has dimension of (batch_size, num_filters, sent_len - filter_sizes[N] + 1)\n","\n","    pools_output = [F.max_pool1d(conv_output, kernel_size = conv_output.shape[-1]).squeeze(2) for conv_output in convs_output]\n","    # Each of the tensor in pools_output has dimension of (batch_size, num_filters) after squeezing\n","\n","    concat = torch.cat(pools_output, dim = 1)\n","    concat = self.dropout(concat)\n","    # concat has dimension of (batch_size, num_filters * len(filter_sizes))\n","\n","    fc_output = self.fc(concat)\n","    # fc_output has dimension of (batch_size, output_dim) after fc layer\n","\n","    return fc_output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9JWdGeNhrE7M","colab_type":"code","colab":{}},"source":["INPUT_DIM = len(TEXT.vocab)\n","EMB_DIM = 100\n","NUM_FILTERS = 100\n","FILTER_SIZES = [2, 3, 4]\n","OUTPUT_DIM = len(LABEL.vocab)\n","DROPOUT = 0.5\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","\n","model = CNN(INPUT_DIM, EMB_DIM, NUM_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n","model = model.to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yZPN1y6es4zE","colab_type":"code","outputId":"c4c91808-3686-4446-c450-08e9f440cf04","executionInfo":{"status":"ok","timestamp":1590632494354,"user_tz":-480,"elapsed":9272,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"execution_count":13,"outputs":[{"output_type":"stream","text":["The model has 1,026,406 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UqsidqA3OYG2","colab_type":"code","outputId":"c3c7dc8e-5bd2-4fff-d619-587edd9d1a10","executionInfo":{"status":"ok","timestamp":1590632495779,"user_tz":-480,"elapsed":1419,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["pretrained_embeddings = TEXT.vocab.vectors\n","print(pretrained_embeddings.shape)\n","model.embedding.weight.data.copy_(pretrained_embeddings)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["torch.Size([9343, 100])\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.3358, -0.0554,  0.3294,  ...,  0.8827,  0.0913, -2.2403],\n","        [-0.0548, -0.7422,  0.8423,  ..., -0.6081,  1.1196, -1.0543],\n","        [ 0.1638,  0.6046,  1.0789,  ..., -0.3140,  0.1844,  0.3624],\n","        ...,\n","        [ 0.0091,  0.2810,  0.7356,  ..., -0.7508,  0.8967, -0.7631],\n","        [ 0.2906,  0.3217,  0.2419,  ..., -0.9444, -0.3790,  0.6196],\n","        [-1.1760,  0.5552,  0.9607,  ...,  1.1343,  0.5196, -0.3769]],\n","       device='cuda:0')"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"9WoROUbwO4zJ","colab_type":"code","outputId":"339d39a6-5b93-4530-c71e-2214f84e546c","executionInfo":{"status":"ok","timestamp":1590632495780,"user_tz":-480,"elapsed":1409,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n","model.embedding.weight.data[UNK_IDX] = torch.zeros(EMB_DIM)\n","model.embedding.weight.data[PAD_IDX] = torch.zeros(EMB_DIM)\n","print(model.embedding.weight.data)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.1638,  0.6046,  1.0789,  ..., -0.3140,  0.1844,  0.3624],\n","        ...,\n","        [ 0.0091,  0.2810,  0.7356,  ..., -0.7508,  0.8967, -0.7631],\n","        [ 0.2906,  0.3217,  0.2419,  ..., -0.9444, -0.3790,  0.6196],\n","        [-1.1760,  0.5552,  0.9607,  ...,  1.1343,  0.5196, -0.3769]],\n","       device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tvB3PqOJtwzj","colab_type":"text"},"source":["# Define loss, metric and optimizer"]},{"cell_type":"code","metadata":{"id":"Q9AbMu09uOGk","colab_type":"code","colab":{}},"source":["import torch.optim as optim\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss()\n","criterion = criterion.to(device)\n","\n","def categorical_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n","    correct = max_preds.squeeze(1).eq(y)\n","    return correct.sum() / torch.FloatTensor([y.shape[0]])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3fvPvuJKv1J0","colab_type":"text"},"source":["# Train Model"]},{"cell_type":"code","metadata":{"id":"0Z4ax_BIv4n0","colab_type":"code","colab":{}},"source":["import time\n","\n","def train_model(model, iterator, optimizer, criterion):\n","  # start of new epoch \n","  start_time = time.time()\n","  epoch_loss = 0\n","  epoch_acc = 0\n","  model.train() # set model to train mdoe to enable dropout and batch norm\n","  batch_size = len(iterator)\n","\n","  for batch in iterator:\n","    optimizer.zero_grad() # set optimizer grad to 0 first\n","    pred = model(batch.text) # forward prop\n","    loss = criterion(pred, batch.label) # calculate loss \n","    acc = categorical_accuracy(pred, batch.label) # calculate metric\n","    loss.backward() # backward prop\n","    optimizer.step() # updates optimizer parameters\n","    epoch_loss += loss.item()\n","    epoch_acc += acc.item()\n","\n","  end_time = time.time()\n","  epoch_time_taken = end_time - start_time\n","\n","  return epoch_loss / batch_size, epoch_acc / batch_size, epoch_time_taken"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ROn2vg4hykAw","colab_type":"code","colab":{}},"source":["from datetime import datetime\n","\n","def evaluate_model(model, iterator, criterion):\n","  # start of new epoch \n","  start_time = time.time()\n","  epoch_loss = 0\n","  epoch_acc = 0\n","  batch_size = len(iterator)\n","  model.eval() # set model to eval mode\n","\n","  for batch in iterator:\n","    pred = model(batch.text) # forward prop\n","    loss = criterion(pred, batch.label) # calculate loss \n","    acc = categorical_accuracy(pred, batch.label) # calculate metric\n","    epoch_loss += loss.item()\n","    epoch_acc += acc.item()\n","\n","  end_time = time.time()\n","  epoch_time_taken = end_time - start_time\n","\n","  return epoch_loss / batch_size, epoch_acc / batch_size, epoch_time_taken"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HqmKMQMp1mV4","colab_type":"code","colab":{}},"source":["import time\n","\n","def convert_time(time_taken):\n","    elapsed_mins = int(time_taken / 60)\n","    elapsed_secs = int(time_taken - (elapsed_mins * 60))\n","    output = f'{elapsed_mins} min and {elapsed_secs} sec'\n","    return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZwsXbles0lUZ","colab_type":"code","outputId":"ca0a8b7d-2779-4a14-a3f8-d9de19c8f305","executionInfo":{"status":"ok","timestamp":1590632753517,"user_tz":-480,"elapsed":8340,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}},"colab":{"base_uri":"https://localhost:8080/","height":527}},"source":["MAX_EPOCHS = 10\n","\n","best_loss = float('inf')\n","for epoch in range(MAX_EPOCHS):\n","  train_loss, train_acc, train_time = train_model(model, train_iterator, optimizer, criterion)\n","  valid_loss, valid_acc, valid_time = evaluate_model(model, valid_iterator, criterion)\n","  print(f'Epoch {epoch} took {convert_time(train_time)} for training and {convert_time(valid_time)} for validation')\n","\n","  if valid_loss < best_loss:\n","    best_loss = valid_loss\n","    torch.save(model.state_dict(), 'model.pt')\n","\n","  print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","  print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Epoch 0 took 0 min and 0 sec for training and 0 min and 0 sec for validation\n","\tTrain Loss: 1.199 | Train Acc: 53.40%\n","\t Val. Loss: 0.787 |  Val. Acc: 72.43%\n","Epoch 1 took 0 min and 0 sec for training and 0 min and 0 sec for validation\n","\tTrain Loss: 0.765 | Train Acc: 72.58%\n","\t Val. Loss: 0.599 |  Val. Acc: 79.39%\n","Epoch 2 took 0 min and 0 sec for training and 0 min and 0 sec for validation\n","\tTrain Loss: 0.550 | Train Acc: 80.79%\n","\t Val. Loss: 0.467 |  Val. Acc: 85.88%\n","Epoch 3 took 0 min and 0 sec for training and 0 min and 0 sec for validation\n","\tTrain Loss: 0.395 | Train Acc: 86.88%\n","\t Val. Loss: 0.403 |  Val. Acc: 87.14%\n","Epoch 4 took 0 min and 0 sec for training and 0 min and 0 sec for validation\n","\tTrain Loss: 0.301 | Train Acc: 89.81%\n","\t Val. Loss: 0.374 |  Val. Acc: 88.78%\n","Epoch 5 took 0 min and 0 sec for training and 0 min and 0 sec for validation\n","\tTrain Loss: 0.228 | Train Acc: 93.04%\n","\t Val. Loss: 0.353 |  Val. Acc: 88.78%\n","Epoch 6 took 0 min and 0 sec for training and 0 min and 0 sec for validation\n","\tTrain Loss: 0.174 | Train Acc: 94.86%\n","\t Val. Loss: 0.322 |  Val. Acc: 90.42%\n","Epoch 7 took 0 min and 0 sec for training and 0 min and 0 sec for validation\n","\tTrain Loss: 0.131 | Train Acc: 96.09%\n","\t Val. Loss: 0.344 |  Val. Acc: 88.35%\n","Epoch 8 took 0 min and 0 sec for training and 0 min and 0 sec for validation\n","\tTrain Loss: 0.099 | Train Acc: 97.55%\n","\t Val. Loss: 0.330 |  Val. Acc: 89.95%\n","Epoch 9 took 0 min and 0 sec for training and 0 min and 0 sec for validation\n","\tTrain Loss: 0.073 | Train Acc: 98.09%\n","\t Val. Loss: 0.328 |  Val. Acc: 89.13%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"00sUvs8sD_3e","colab_type":"text"},"source":["# Inference on test set"]},{"cell_type":"code","metadata":{"id":"g_VuftmgECHo","colab_type":"code","outputId":"89fb41e9-6a9f-4375-d170-00babcb67cb8","executionInfo":{"status":"ok","timestamp":1590632759319,"user_tz":-480,"elapsed":1112,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["model.load_state_dict(torch.load('model.pt'))\n","test_loss, test_acc, test_time = evaluate_model(model, test_iterator, criterion)\n","print(f'Epoch {epoch} took {convert_time(test_time)} for test')\n","print(f'\\t Test. Loss: {test_loss:.3f} |  Test. Acc: {test_acc*100:.2f}%')"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Epoch 9 took 0 min and 0 sec for test\n","\t Test. Loss: 0.278 |  Test. Acc: 91.08%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4amb0sOlU1RN","colab_type":"text"},"source":["# User Input"]},{"cell_type":"code","metadata":{"id":"WDYbcT7iU20G","colab_type":"code","colab":{}},"source":["import spacy\n","nlp = spacy.load('en')\n","\n","def predict_class(model, sentence, min_len = 4):\n","\n","    model.eval()\n","    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n","    if len(tokenized) < min_len:\n","        tokenized += ['<pad>'] * (min_len - len(tokenized))\n","    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n","    tensor = torch.LongTensor(indexed).to(device)\n","    tensor = tensor.unsqueeze(0)\n","    pred = model(tensor)\n","    prediction = pred.argmax(dim=1)\n","    return prediction.item()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MP63IYnYWRjQ","colab_type":"code","outputId":"67154572-cee8-44ab-b6ea-73ba7a4414cb","executionInfo":{"status":"ok","timestamp":1590633053455,"user_tz":-480,"elapsed":1114,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["pred_class = predict_class(model, \"Who is Justin Bieber?\")\n","print(f'Predicted class is: {pred_class} = {LABEL.vocab.itos[pred_class]}')"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Predicted class is: 1 = HUM\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SPySvg-wWRlm","colab_type":"code","outputId":"47e6b2ce-d369-4eb7-aa04-38529f4362db","executionInfo":{"status":"ok","timestamp":1590633043987,"user_tz":-480,"elapsed":1095,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["pred_class = predict_class(model, \"How many apples does she have?\")\n","print(f'Predicted class is: {pred_class} = {LABEL.vocab.itos[pred_class]}')"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Predicted class is: 3 = NUM\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ExkKtBDDHHlb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e245b5c4-ed67-4889-8a29-9ff5b9d74b06","executionInfo":{"status":"ok","timestamp":1590633001498,"user_tz":-480,"elapsed":1087,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}}},"source":["pred_class = predict_class(model, \"What continent is Singapore in?\")\n","print(f'Predicted class is: {pred_class} = {LABEL.vocab.itos[pred_class]}')"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Predicted class is: 4 = LOC\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LqZS6u1fHHmv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f4a6a682-9433-4178-c157-27b2a4623930","executionInfo":{"status":"ok","timestamp":1590633010039,"user_tz":-480,"elapsed":1276,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}}},"source":["pred_class = predict_class(model, \"What does LOL stand for?\")\n","print(f'Predicted class is: {pred_class} = {LABEL.vocab.itos[pred_class]}')"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Predicted class is: 5 = ABBR\n"],"name":"stdout"}]}]}