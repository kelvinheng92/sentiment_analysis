{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of baseline.ipynb","provenance":[{"file_id":"https://github.com/kelvinheng92/sentiment_analysis/blob/master/baseline.ipynb","timestamp":1589417551888}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"D0fSKmcvTUU3","colab_type":"text"},"source":["# Data Preparation"]},{"cell_type":"code","metadata":{"id":"L1xB2xwRTZKg","colab_type":"code","colab":{}},"source":["import torch\n","from torchtext import data, datasets\n","import random\n","\n","SEED = 1992\n","\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","TEXT = data.Field(tokenize = 'spacy')\n","LABEL = data.LabelField(dtype = torch.float)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jxyR5l5oTjAh","colab_type":"code","colab":{}},"source":["train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ddKoNplZUY7Q","colab_type":"code","outputId":"e5c62cf6-0c1d-4a06-cf49-b609120aae74","executionInfo":{"status":"ok","timestamp":1589421758535,"user_tz":-480,"elapsed":71046,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(f'Number of training examples: {len(train_data)}')\n","print(f'Number of testing examples: {len(test_data)}')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Number of training examples: 25000\n","Number of testing examples: 25000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IhV_vj1GUuZZ","colab_type":"code","outputId":"e0a615ff-ace8-4c05-bdc2-7509ef14751d","executionInfo":{"status":"ok","timestamp":1589421758536,"user_tz":-480,"elapsed":71038,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["print(vars(train_data.examples[0]))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["{'text': ['Chalk', 'this', 'one', 'up', 'in', 'the', 'win', 'column', ',', 'this', 'was', 'a', 'superb', 'movie', '.', 'The', 'acting', 'performances', 'were', 'great', 'and', 'the', 'script', 'was', 'equally', 'great.<br', '/><br', '/>Helen', 'Hunt', 'was', 'magnificent', 'as', 'the', 'Riverside', 'police', 'officer', 'Gina', 'Pulasky', '.', 'Gina', 'was', 'a', 'complex', 'character', '.', 'She', 'was', 'a', 'rookie', 'cop', 'with', 'the', 'Riverside', 'Police', 'Dept', '.', 'She', 'ended', 'up', 'in', 'an', 'affair', 'with', 'a', 'coworker', 'that', 'she', 'knew', 'had', 'a', 'wife', 'and', 'kids', ',', 'all', 'the', 'while', 'she', 'took', 'on', 'the', 'dangerous', 'task', 'of', 'going', 'undercover', 'to', 'catch', 'a', 'serial', 'killer', '.', '<', 'br', '/><br', '/>Jeff', 'Fahey', '(', 'the', 'Ray', 'Liotta', 'look', 'alike', ')', 'did', 'a', 'bang', 'up', 'job', 'as', 'the', 'confused', ',', 'often', 'stammering', ',', 'police', 'officer', 'that', 'had', 'an', 'affair', 'with', 'Gina', '.', 'He', 'was', 'stoic', 'as', 'an', 'officer', ',', 'but', 'he', 'was', 'quite', 'the', 'opposite', 'when', 'it', 'came', 'to', 'dealing', 'with', 'his', 'feelings', 'and', 'his', 'extra', '-', 'marital', 'affair.<br', '/><br', '/>Steven', 'Weber', ',', 'most', 'notably', 'from', 'the', 'sitcom', '\"', 'Wings', '\"', ',', 'did', 'a', 'nice', 'job', 'as', 'the', 'quiet', ',', 'meek', ',', 'underachieving', 'sociopath', '.', 'On', 'the', 'surface', ',', 'he', 'was', 'an', 'innocent', 'loser', ',', 'but', 'beneath', 'the', 'surface', 'lied', 'a', 'cold', 'hearted', 'killer', '.', 'Weber', 'really', 'took', 'on', 'the', 'persona', 'of', 'a', 'childlike', 'young', 'adult', 'with', 'an', 'insatiable', 'thirst', 'to', 'kill', 'young', 'boys.<br', '/><br', '/>The', 'entire', 'movie', 'was', 'spectacular', '.', 'Each', 'scene', ',', 'each', 'verbal', 'exchange', 'let', 'us', 'know', 'more', 'and', 'more', 'about', 'the', 'characters', '.', 'The', 'production', 'team', 'did', 'a', 'phenomenal', 'job', 'with', 'condensing', 'days', ',', 'if', 'not', 'weeks', 'worth', 'of', 'events', 'into', 'a', '90', 'minute', 'movie', '.', 'This', 'movie', 'was', 'a', 'good', 'example', 'of', 'doing', 'a', 'lot', 'with', 'little', '.'], 'label': 'pos'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"byg-goSAjMy1","colab_type":"code","colab":{}},"source":["valid_data, test_data = test_data.split(split_ratio = 0.5, random_state = random.seed(SEED)) #Further split test set into validation and test set"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OT_sjF_ZlMCg","colab_type":"code","outputId":"cb197190-1a15-4971-9e56-a3f872c5d11d","executionInfo":{"status":"ok","timestamp":1589421758537,"user_tz":-480,"elapsed":71024,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["print(f'Number of training examples: {len(train_data)}')\n","print(f'Number of validation examples: {len(valid_data)}')\n","print(f'Number of testing examples: {len(test_data)}')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Number of training examples: 25000\n","Number of validation examples: 12500\n","Number of testing examples: 12500\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DW8OoSamoN_5","colab_type":"code","colab":{}},"source":["MAX_VOCAB_SIZE = 25_000\n","TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n","LABEL.build_vocab(train_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xKpI5orppdF4","colab_type":"code","outputId":"3d1e6b92-3485-4d1f-a0f1-14beb5b7f92d","executionInfo":{"status":"ok","timestamp":1589421759692,"user_tz":-480,"elapsed":72163,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["vars(LABEL.vocab)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'freqs': Counter({'neg': 12500, 'pos': 12500}),\n"," 'itos': ['neg', 'pos'],\n"," 'stoi': defaultdict(<function torchtext.vocab._default_unk_index>,\n","             {'neg': 0, 'pos': 1}),\n"," 'vectors': None}"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"_zHC1He0oqbn","colab_type":"code","outputId":"282558b4-a109-464f-eaa6-d6db2837ea55","executionInfo":{"status":"ok","timestamp":1589421759693,"user_tz":-480,"elapsed":72155,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(f'There are {len(TEXT.vocab)} unique tokens in TEXT vocabulary')\n","print(f'There are {len(LABEL.vocab)} unique tokens in LABEL vocabulary')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["There are 25002 unique tokens in TEXT vocabulary\n","There are 2 unique tokens in LABEL vocabulary\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mwaiWFisr1IW","colab_type":"code","outputId":"de5293c2-d76f-4fc9-c6da-51fdfb5a5b74","executionInfo":{"status":"ok","timestamp":1589421759693,"user_tz":-480,"elapsed":72145,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(vars(TEXT.vocab).keys())\n","print(vars(LABEL.vocab).keys())"],"execution_count":10,"outputs":[{"output_type":"stream","text":["dict_keys(['freqs', 'itos', 'stoi', 'vectors'])\n","dict_keys(['freqs', 'itos', 'stoi', 'vectors'])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Oa95Dc4WrQ4l","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 64\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits((train_data, valid_data, test_data),\n","                                                                           batch_size = BATCH_SIZE,\n","                                                                           device = device)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zk5IUombrJRC","colab_type":"text"},"source":["# Model Architecture"]},{"cell_type":"code","metadata":{"id":"V0GhJG2Jt3I_","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","\n","class baseline_rnn(nn.Module):\n","  def __init__(self, input_dim, emb_dim, hidden_dim, output_dim):\n","    super().__init__() # init from super class in nn.module\n","    self.embedding = nn.Embedding(input_dim, emb_dim)\n","    self.rnn = nn.RNN(emb_dim, hidden_dim, num_layers = 1, nonlinearity = 'relu', bias=True, bidirectional=False)\n","    self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","  def forward(self, text):\n","    # text has dimension of (sentence_length, batch_size)\n","    embedding_output = self.embedding(text) \n","    # embedding_output has dimension of (sentence_length, batch_size, emb_dim)\n","    rnn_output, rnn_hidden = self.rnn(embedding_output) \n","    # rnn_output has dimension of (sentence_length, batch_size, num_directions * hidden_dim) where num_directions = 2 if bidirectional RNN\n","    # rnn_hidden has dimension of (num_directions * num_layers, batch_size, hidden_dim) where num_directions = 2 if bidirectional RNN and num_layers (if it is stacked RNN)\n","    rnn_hidden = rnn_hidden.squeeze(0)\n","    # rnn_hidden has dimension of (batch_size, hidden_dim) after squeezeing\n","    fc_output = self.fc(rnn_output)\n","    # fc_output has dimension of (batch_size, output_dim) after fc layer\n","\n","    return fc_output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9JWdGeNhrE7M","colab_type":"code","colab":{}},"source":["INPUT_DIM = len(TEXT.vocab)\n","EMB_DIM = 128\n","HIDDEN_DIM = 256\n","OUTPUT_DIM = 1\n","\n","model = baseline_rnn(INPUT_DIM, EMB_DIM, HIDDEN_DIM, OUTPUT_DIM)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yZPN1y6es4zE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"a16ba129-da3f-4662-edf6-a5ac04925bb5","executionInfo":{"status":"ok","timestamp":1589421759697,"user_tz":-480,"elapsed":72119,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}}},"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["The model has 3,299,329 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tvB3PqOJtwzj","colab_type":"text"},"source":["# Define loss, metric and optimizer"]},{"cell_type":"code","metadata":{"id":"Q9AbMu09uOGk","colab_type":"code","colab":{}},"source":["import torch.optim as optim\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.BCEWithLogitsLoss()\n","\n","def binary_accuracy(preds, label):\n","\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == label).float() \n","    acc = correct.sum() / len(correct)\n","    return acc"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3fvPvuJKv1J0","colab_type":"text"},"source":["# Train Model"]},{"cell_type":"code","metadata":{"id":"0Z4ax_BIv4n0","colab_type":"code","colab":{}},"source":["from datetime import datetime\n","\n","def train_model(model, iterator, optimizer, criterion):\n","  # start of new epoch \n","  start_time = datetime.now()\n","  epoch_loss = 0\n","  epoch_acc = 0\n","  model.train() # set model to train mdoe to enable dropout and batch norm\n","\n","  for batch in iterator:\n","    curr_batch_size = vars(batch)['batch_size']\n","    optimizer.zero_grad() # set optimizer grad to 0 first\n","    pred = model(batch.text).squeeze(1) # forward prop\n","    loss = criterion(pred, batch.label) # calculate loss \n","    acc = binary_accuracy(pred, label) # calculate metric\n","    loss.backward() # backward prop\n","    optimizer.step() # updates optimizer parameters\n","    epoch_loss += loss.item()\n","    epoch_acc += acc.item()\n","\n","  end_time = datetime.now()\n","  epoch_time_taken = end_time - start_time\n","\n","  return epoch_loss / curr_batch_size, epoch_acc / curr_batch_size, epoch_time_taken"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ROn2vg4hykAw","colab_type":"code","colab":{}},"source":["from datetime import datetime\n","\n","def evaluate_model(model, iterator, criterion):\n","  # start of new epoch \n","  start_time = datetime.now()\n","  epoch_loss = 0\n","  epoch_acc = 0\n","  model.eval() # set model to eval mode\n","\n","  for batch in iterator:\n","    curr_batch_size = vars(batch)['batch_size']\n","    pred = model(batch.text).squeeze(1) # forward prop\n","    loss = criterion(pred, batch.label) # calculate loss \n","    acc = binary_accuracy(pred, label) # calculate metric\n","    epoch_loss += loss.item()\n","    epoch_acc += acc.item()\n","\n","  end_time = datetime.now()\n","  epoch_time_taken = end_time - start_time\n","\n","  return epoch_loss / curr_batch_size, epoch_acc / curr_batch_size, epoch_time_taken"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HqmKMQMp1mV4","colab_type":"code","colab":{}},"source":["def convert_time(time_taken):\n","  return f'{time_taken.days} days, {time_taken.min} minutes and {time_taken.seconds} seconds'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZwsXbles0lUZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":375},"outputId":"134c0753-8e64-4837-f6e7-890cf06d6dd1","executionInfo":{"status":"error","timestamp":1589421762831,"user_tz":-480,"elapsed":75215,"user":{"displayName":"Kelvin Heng","photoUrl":"","userId":"16189608668730772404"}}},"source":["MAX_EPOCHS = 10\n","\n","best_loss = float('inf')\n","for epoch in range(MAX_EPOCHS):\n","  train_loss, train_acc, train_time = train_model(model, train_iterator, optimizer, criterion)\n","  valid_loss, valid_acc, valid_time = evaluate_model(model, valid_iterator, criterion)\n","  print(f'Epoch {epoch} took {convert_time(train_time)} for training and {convert_time(valid_time)} for validation')\n","\n","  if valid_loss < best_loss:\n","    best_loss = valid_loss\n","    torch.save(model.state_dict(), 'baseline_model.pt')\n","\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"],"execution_count":19,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-4bbad789b012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch} took {convert_time(train_time)} for training and {convert_time(valid_time)} for validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-6a33914d7529>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcurr_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# set optimizer grad to 0 first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# forward prop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# calculate metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-c1034e60c284>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# text has dimension of (sentence_length, batch_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m# embedding_output has dimension of (sentence_length, batch_size, emb_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mrnn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1722\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1724\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_index_select"]}]}]}